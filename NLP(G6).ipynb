{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VenkataSunil18/Online-payment-Fraud-Detection/blob/main/NLP(G6).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "suzbLHahTYIa",
        "outputId": "ed90538d-0f4e-461d-d3be-29eeff483ad8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.67.1)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1.Write a python NLTK program to remove stop words from a given text**"
      ],
      "metadata": {
        "id": "p--AitDyUEmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "text = \"In computing, stop words are words which are filtered out before or after processing of natural language data.\"\n",
        "stop_words = set(stopwords.words('english'))\n",
        "word_tokens = word_tokenize(text)\n",
        "filtered_text = [word for word in text.split() if word.lower() not in stop_words]\n",
        "print(\"\\nOriginal text:\", text)\n",
        "print(\"\\nFiltered text:\",filtered_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbbxBVf2TiYP",
        "outputId": "3aae0e6c-9fbb-4efb-b979-5d878436468e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original text: In computing, stop words are words which are filtered out before or after processing of natural language data.\n",
            "\n",
            "Filtered text: ['computing,', 'stop', 'words', 'words', 'filtered', 'processing', 'natural', 'language', 'data.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2.Write a python NLTK program to split the text sentence/paragraph into a list of words**"
      ],
      "metadata": {
        "id": "CKcX_gs3VDCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "text = '''Hi this is Sunil.\n",
        "from cse(ds)\n",
        "'''\n",
        "print(\"\\nOriginal string:\")\n",
        "print(text)\n",
        "token_text = sent_tokenize(text)\n",
        "print(\"\\nSentence-tokenized copy in a list:\")\n",
        "print(token_text)\n",
        "print(\"\\nRead the list:\")\n",
        "for s in token_text:\n",
        "    print(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qedyrE-TigT",
        "outputId": "1492688b-4263-4930-b1da-a6bfa6d0d342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original string:\n",
            "Hi this is Sunil.\n",
            "from cse(ds)\n",
            "\n",
            "\n",
            "Sentence-tokenized copy in a list:\n",
            "['Hi this is Sunil.', 'from cse(ds)']\n",
            "\n",
            "Read the list:\n",
            "Hi this is Sunil.\n",
            "from cse(ds)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q3.Write a Python NLTK program to tokenize sentences in languages other than English.**"
      ],
      "metadata": {
        "id": "AVJqgEzuVh7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "text = '''\n",
        "NLTK is the Open Source Software. Der Quellcode wird unter den Bedingungen der Apache License Version 2.0 vertrieben.\n",
        "Die Dokumentation wird unter den Bedingungen der Creative Commons-Lizenz Namensnennung - Nicht kommerziell - Keine\n",
        "abgeleiteten Werke 3.0 in den Vereinigten Staaten verteilt.\n",
        "'''\n",
        "print(\"\\nOriginal string:\")\n",
        "print(text)\n",
        "token_text = sent_tokenize(text, language='german')\n",
        "print(\"\\nSentence-tokenized copy in a list:\")\n",
        "print(token_text)\n",
        "print(\"\\nRead the list:\")\n",
        "for i in token_text:\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdlGHW-ITikz",
        "outputId": "8411198e-3141-4456-8926-61ddf58917e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original string:\n",
            "\n",
            "NLTK is the Open Source Software. Der Quellcode wird unter den Bedingungen der Apache License Version 2.0 vertrieben.  \n",
            "Die Dokumentation wird unter den Bedingungen der Creative Commons-Lizenz Namensnennung - Nicht kommerziell - Keine \n",
            "abgeleiteten Werke 3.0 in den Vereinigten Staaten verteilt.\n",
            "\n",
            "\n",
            "Sentence-tokenized copy in a list:\n",
            "['\\nNLTK is the Open Source Software.', 'Der Quellcode wird unter den Bedingungen der Apache License Version 2.0 vertrieben.', 'Die Dokumentation wird unter den Bedingungen der Creative Commons-Lizenz Namensnennung - Nicht kommerziell - Keine \\nabgeleiteten Werke 3.0 in den Vereinigten Staaten verteilt.']\n",
            "\n",
            "Read the list:\n",
            "\n",
            "NLTK is the Open Source Software.\n",
            "Der Quellcode wird unter den Bedingungen der Apache License Version 2.0 vertrieben.\n",
            "Die Dokumentation wird unter den Bedingungen der Creative Commons-Lizenz Namensnennung - Nicht kommerziell - Keine \n",
            "abgeleiteten Werke 3.0 in den Vereinigten Staaten verteilt.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q4.Write a python NLTK program to create a list of words from a given string**"
      ],
      "metadata": {
        "id": "njY93Ui7V1JS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "text = \"Joe waited for the train. The train was late. Mary and Samantha took the bus. I looked for Mary and Samantha at the bus station.\"\n",
        "print(\"\\nOriginal string:\")\n",
        "print(text)\n",
        "print(\"\\nList of words:\")\n",
        "print(word_tokenize(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JAdx-FYTioD",
        "outputId": "776116c9-8318-454b-b7d2-41a078267bf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original string:\n",
            "Joe waited for the train. The train was late. Mary and Samantha took the bus. I looked for Mary and Samantha at the bus station.\n",
            "\n",
            "List of words:\n",
            "['Joe', 'waited', 'for', 'the', 'train', '.', 'The', 'train', 'was', 'late', '.', 'Mary', 'and', 'Samantha', 'took', 'the', 'bus', '.', 'I', 'looked', 'for', 'Mary', 'and', 'Samantha', 'at', 'the', 'bus', 'station', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q5.Write a NLTK program list down all the corpus names.**"
      ],
      "metadata": {
        "id": "A_wCVRyTWIIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk.corpus\n",
        "dir(nltk.corpus)\n",
        "print(\"\\nAvailable corpus names:\")\n",
        "print(dir(nltk.corpus))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WW6wNjidWB8K",
        "outputId": "b88b41d9-f5f5-48bc-8ca1-bfd3a976f8af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Available corpus names:\n",
            "['_LazyModule__lazymodule_globals', '_LazyModule__lazymodule_import', '_LazyModule__lazymodule_init', '_LazyModule__lazymodule_loaded', '_LazyModule__lazymodule_locals', '_LazyModule__lazymodule_name', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q6.Write a python NLTK program to get a list of common stop words in various languages in python**"
      ],
      "metadata": {
        "id": "z7stpB9SWTiz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "print (stopwords.fileids())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGnZtqkWWDCz",
        "outputId": "2ea0212d-3f98-43ca-b43d-5e738cdf860a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['arabic', 'azerbaijani', 'basque', 'bengali', 'catalan', 'chinese', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'greek', 'hebrew', 'hinglish', 'hungarian', 'indonesian', 'italian', 'kazakh', 'nepali', 'norwegian', 'portuguese', 'romanian', 'russian', 'slovene', 'spanish', 'swedish', 'tajik', 'turkish']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "print(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bfq7PMb8WDJD",
        "outputId": "727136c4-0580-45e8-9c31-4e72b2d86153"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "languages=stopwords.fileids()\n",
        "print(\"Available languages and their stopwords:\\n\")\n",
        "for lang in languages:\n",
        "    print(f\"Language: {lang}\")\n",
        "    print(f\"Stopwords: ({lang}):\")\n",
        "    print(\", \".join(stopwords.words(lang)[:10]))\n",
        "    print(\"\\n----\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sh7ReGWMWDL7",
        "outputId": "11e583dc-04d7-4813-dbce-be7807a8027c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available languages and their stopwords:\n",
            "\n",
            "Language: arabic\n",
            "Stopwords: (arabic):\n",
            "إذ, إذا, إذما, إذن, أف, أقل, أكثر, ألا, إلا, التي\n",
            "\n",
            "----\n",
            "\n",
            "Language: azerbaijani\n",
            "Stopwords: (azerbaijani):\n",
            "a, ad, altı, altmış, amma, arasında, artıq, ay, az, bax\n",
            "\n",
            "----\n",
            "\n",
            "Language: basque\n",
            "Stopwords: (basque):\n",
            "ahala, aitzitik, al, ala , alabadere, alabaina, alabaina, aldiz , alta, amaitu\n",
            "\n",
            "----\n",
            "\n",
            "Language: bengali\n",
            "Stopwords: (bengali):\n",
            "অতএব, অথচ, অথবা, অনুযায়ী, অনেক, অনেকে, অনেকেই, অন্তত, অন্য, অবধি\n",
            "\n",
            "----\n",
            "\n",
            "Language: catalan\n",
            "Stopwords: (catalan):\n",
            "a, abans, ací, ah, així, això, al, aleshores, algun, alguna\n",
            "\n",
            "----\n",
            "\n",
            "Language: chinese\n",
            "Stopwords: (chinese):\n",
            "一, 一下, 一些, 一切, 一则, 一天, 一定, 一方面, 一旦, 一时\n",
            "\n",
            "----\n",
            "\n",
            "Language: danish\n",
            "Stopwords: (danish):\n",
            "og, i, jeg, det, at, en, den, til, er, som\n",
            "\n",
            "----\n",
            "\n",
            "Language: dutch\n",
            "Stopwords: (dutch):\n",
            "de, en, van, ik, te, dat, die, in, een, hij\n",
            "\n",
            "----\n",
            "\n",
            "Language: english\n",
            "Stopwords: (english):\n",
            "i, me, my, myself, we, our, ours, ourselves, you, you're\n",
            "\n",
            "----\n",
            "\n",
            "Language: finnish\n",
            "Stopwords: (finnish):\n",
            "olla, olen, olet, on, olemme, olette, ovat, ole, oli, olisi\n",
            "\n",
            "----\n",
            "\n",
            "Language: french\n",
            "Stopwords: (french):\n",
            "au, aux, avec, ce, ces, dans, de, des, du, elle\n",
            "\n",
            "----\n",
            "\n",
            "Language: german\n",
            "Stopwords: (german):\n",
            "aber, alle, allem, allen, aller, alles, als, also, am, an\n",
            "\n",
            "----\n",
            "\n",
            "Language: greek\n",
            "Stopwords: (greek):\n",
            "αλλα, αν, αντι, απο, αυτα, αυτεσ, αυτη, αυτο, αυτοι, αυτοσ\n",
            "\n",
            "----\n",
            "\n",
            "Language: hebrew\n",
            "Stopwords: (hebrew):\n",
            "אני, את, אתה, אנחנו, אתן, אתם, הם, הן, היא, הוא\n",
            "\n",
            "----\n",
            "\n",
            "Language: hinglish\n",
            "Stopwords: (hinglish):\n",
            "a, aadi, aaj, aap, aapne, aata, aati, aaya, aaye, ab\n",
            "\n",
            "----\n",
            "\n",
            "Language: hungarian\n",
            "Stopwords: (hungarian):\n",
            "a, ahogy, ahol, aki, akik, akkor, alatt, által, általában, amely\n",
            "\n",
            "----\n",
            "\n",
            "Language: indonesian\n",
            "Stopwords: (indonesian):\n",
            "ada, adalah, adanya, adapun, agak, agaknya, agar, akan, akankah, akhir\n",
            "\n",
            "----\n",
            "\n",
            "Language: italian\n",
            "Stopwords: (italian):\n",
            "ad, al, allo, ai, agli, all, agl, alla, alle, con\n",
            "\n",
            "----\n",
            "\n",
            "Language: kazakh\n",
            "Stopwords: (kazakh):\n",
            "ах, ох, эх, ай, эй, ой, тағы, тағыда, әрине, жоқ\n",
            "\n",
            "----\n",
            "\n",
            "Language: nepali\n",
            "Stopwords: (nepali):\n",
            "छ, र, पनि, छन्, लागि, भएको, गरेको, भने, गर्न, गर्ने\n",
            "\n",
            "----\n",
            "\n",
            "Language: norwegian\n",
            "Stopwords: (norwegian):\n",
            "og, i, jeg, det, at, en, et, den, til, er\n",
            "\n",
            "----\n",
            "\n",
            "Language: portuguese\n",
            "Stopwords: (portuguese):\n",
            "a, à, ao, aos, aquela, aquelas, aquele, aqueles, aquilo, as\n",
            "\n",
            "----\n",
            "\n",
            "Language: romanian\n",
            "Stopwords: (romanian):\n",
            "a, abia, acea, aceasta, această, aceea, aceeasi, acei, aceia, acel\n",
            "\n",
            "----\n",
            "\n",
            "Language: russian\n",
            "Stopwords: (russian):\n",
            "и, в, во, не, что, он, на, я, с, со\n",
            "\n",
            "----\n",
            "\n",
            "Language: slovene\n",
            "Stopwords: (slovene):\n",
            "ali, ampak, bodisi, in, kajti, marveč, namreč, ne, niti, oziroma\n",
            "\n",
            "----\n",
            "\n",
            "Language: spanish\n",
            "Stopwords: (spanish):\n",
            "de, la, que, el, en, y, a, los, del, se\n",
            "\n",
            "----\n",
            "\n",
            "Language: swedish\n",
            "Stopwords: (swedish):\n",
            "och, det, att, i, en, jag, hon, som, han, på\n",
            "\n",
            "----\n",
            "\n",
            "Language: tajik\n",
            "Stopwords: (tajik):\n",
            "аз, дар, ба, бо, барои, бе, то, ҷуз, пеши, назди\n",
            "\n",
            "----\n",
            "\n",
            "Language: turkish\n",
            "Stopwords: (turkish):\n",
            "acaba, ama, aslında, az, bazı, belki, biri, birkaç, birşey, biz\n",
            "\n",
            "----\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q7.Write a python NLTK program to find the definition and examples of a given word using WordNet**"
      ],
      "metadata": {
        "id": "mV5JHZvFTqxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "nltk.download('wordnet')\n",
        "syns = wordnet.synsets(\"free\")\n",
        "print(\"Defination of the said word:\")\n",
        "print(syns[0].definition())\n",
        "print(\"\\nExamples of the word in use::\")\n",
        "print(syns[0].examples())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33Dc4gDyTirD",
        "outputId": "4e9751e0-4d4b-42c7-d0d8-c0ad52ff8380"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defination of the said word:\n",
            "people who are free\n",
            "\n",
            "Examples of the word in use::\n",
            "['the home of the free and the brave']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q8.Write a python NLTK program to find the sets of synonyms and antonyms of a given word**"
      ],
      "metadata": {
        "id": "J8qGKmN3XUma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import wordnet\n",
        "synonyms = []\n",
        "antonyms = []\n",
        "\n",
        "for syn in wordnet.synsets(\"happy\"):\n",
        "    for l in syn.lemmas():\n",
        "        synonyms.append(l.name())\n",
        "        if l.antonyms():\n",
        "            antonyms.append(l.antonyms()[0].name())\n",
        "print(\"\\nSet of synonyms of the said word:\")\n",
        "print(set(synonyms))\n",
        "print(\"\\nSet of antonyms of the said word:\")\n",
        "print(set(antonyms))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97qdAS7cT1yT",
        "outputId": "418d6859-ead3-41e2-91b8-51b08eef5019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Set of synonyms of the said word:\n",
            "{'felicitous', 'glad', 'happy', 'well-chosen'}\n",
            "\n",
            "Set of antonyms of the said word:\n",
            "{'unhappy'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q9.Write a python NLTK program to get the overview of the tagset,details of a specific tag in the tagset and details on several related tagsets, using regular expression.**"
      ],
      "metadata": {
        "id": "Vmz_APp9XbvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('tagsets_json')\n",
        "print(\"Overview of the tagset:\")\n",
        "print(nltk.help.brown_tagset())\n",
        "print(\"\\nDetails of a specific tag :\")\n",
        "print(nltk.help.brown_tagset(r'NNS'))\n",
        "print(\"\\nDetails on several related tagsets, using regular expression:\")\n",
        "nltk.help.brown_tagset(r'WP*')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9cWFQtVXmtq",
        "outputId": "05d40001-aef7-4506-e4e0-ce702cda1687"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overview of the tagset:\n",
            "(: opening parenthesis\n",
            "    (\n",
            "): closing parenthesis\n",
            "    )\n",
            "*: negator\n",
            "    not n't\n",
            ",: comma\n",
            "    ,\n",
            "--: dash\n",
            "    --\n",
            ".: sentence terminator\n",
            "    . ? ; ! :\n",
            ":: colon\n",
            "    :\n",
            "ABL: determiner/pronoun, pre-qualifier\n",
            "    quite such rather\n",
            "ABN: determiner/pronoun, pre-quantifier\n",
            "    all half many nary\n",
            "ABX: determiner/pronoun, double conjunction or pre-quantifier\n",
            "    both\n",
            "AP: determiner/pronoun, post-determiner\n",
            "    many other next more last former little several enough most least only\n",
            "    very few fewer past same Last latter less single plenty 'nough lesser\n",
            "    certain various manye next-to-last particular final previous present\n",
            "    nuf\n",
            "AP$: determiner/pronoun, post-determiner, genitive\n",
            "    other's\n",
            "AP+AP: determiner/pronoun, post-determiner, hyphenated pair\n",
            "    many-much\n",
            "AT: article\n",
            "    the an no a every th' ever' ye\n",
            "BE: verb 'to be', infinitive or imperative\n",
            "    be\n",
            "BED: verb 'to be', past tense, 2nd person singular or all persons plural\n",
            "    were\n",
            "BED*: verb 'to be', past tense, 2nd person singular or all persons plural, negated\n",
            "    weren't\n",
            "BEDZ: verb 'to be', past tense, 1st and 3rd person singular\n",
            "    was\n",
            "BEDZ*: verb 'to be', past tense, 1st and 3rd person singular, negated\n",
            "    wasn't\n",
            "BEG: verb 'to be', present participle or gerund\n",
            "    being\n",
            "BEM: verb 'to be', present tense, 1st person singular\n",
            "    am\n",
            "BEM*: verb 'to be', present tense, 1st person singular, negated\n",
            "    ain't\n",
            "BEN: verb 'to be', past participle\n",
            "    been\n",
            "BER: verb 'to be', present tense, 2nd person singular or all persons plural\n",
            "    are art\n",
            "BER*: verb 'to be', present tense, 2nd person singular or all persons plural, negated\n",
            "    aren't ain't\n",
            "BEZ: verb 'to be', present tense, 3rd person singular\n",
            "    is\n",
            "BEZ*: verb 'to be', present tense, 3rd person singular, negated\n",
            "    isn't ain't\n",
            "CC: conjunction, coordinating\n",
            "    and or but plus & either neither nor yet 'n' and/or minus an'\n",
            "CD: numeral, cardinal\n",
            "    two one 1 four 2 1913 71 74 637 1937 8 five three million 87-31 29-5\n",
            "    seven 1,119 fifty-three 7.5 billion hundred 125,000 1,700 60 100 six\n",
            "    ...\n",
            "CD$: numeral, cardinal, genitive\n",
            "    1960's 1961's .404's\n",
            "CS: conjunction, subordinating\n",
            "    that as after whether before while like because if since for than altho\n",
            "    until so unless though providing once lest s'posin' till whereas\n",
            "    whereupon supposing tho' albeit then so's 'fore\n",
            "DO: verb 'to do', uninflected present tense, infinitive or imperative\n",
            "    do dost\n",
            "DO*: verb 'to do', uninflected present tense or imperative, negated\n",
            "    don't\n",
            "DO+PPSS: verb 'to do', past or present tense + pronoun, personal, nominative, not 3rd person singular\n",
            "    d'you\n",
            "DOD: verb 'to do', past tense\n",
            "    did done\n",
            "DOD*: verb 'to do', past tense, negated\n",
            "    didn't\n",
            "DOZ: verb 'to do', present tense, 3rd person singular\n",
            "    does\n",
            "DOZ*: verb 'to do', present tense, 3rd person singular, negated\n",
            "    doesn't don't\n",
            "DT: determiner/pronoun, singular\n",
            "    this each another that 'nother\n",
            "DT$: determiner/pronoun, singular, genitive\n",
            "    another's\n",
            "DT+BEZ: determiner/pronoun + verb 'to be', present tense, 3rd person singular\n",
            "    that's\n",
            "DT+MD: determiner/pronoun + modal auxillary\n",
            "    that'll this'll\n",
            "DTI: determiner/pronoun, singular or plural\n",
            "    any some\n",
            "DTS: determiner/pronoun, plural\n",
            "    these those them\n",
            "DTS+BEZ: pronoun, plural + verb 'to be', present tense, 3rd person singular\n",
            "    them's\n",
            "DTX: determiner, pronoun or double conjunction\n",
            "    neither either one\n",
            "EX: existential there\n",
            "    there\n",
            "EX+BEZ: existential there + verb 'to be', present tense, 3rd person singular\n",
            "    there's\n",
            "EX+HVD: existential there + verb 'to have', past tense\n",
            "    there'd\n",
            "EX+HVZ: existential there + verb 'to have', present tense, 3rd person singular\n",
            "    there's\n",
            "EX+MD: existential there + modal auxillary\n",
            "    there'll there'd\n",
            "FW-*: foreign word: negator\n",
            "    pas non ne\n",
            "FW-AT: foreign word: article\n",
            "    la le el un die der ein keine eine das las les Il\n",
            "FW-AT+NN: foreign word: article + noun, singular, common\n",
            "    l'orchestre l'identite l'arcade l'ange l'assistance l'activite\n",
            "    L'Universite l'independance L'Union L'Unita l'osservatore\n",
            "FW-AT+NP: foreign word: article + noun, singular, proper\n",
            "    L'Astree L'Imperiale\n",
            "FW-BE: foreign word: verb 'to be', infinitive or imperative\n",
            "    sit\n",
            "FW-BER: foreign word: verb 'to be', present tense, 2nd person singular or all persons plural\n",
            "    sind sunt etes\n",
            "FW-BEZ: foreign word: verb 'to be', present tense, 3rd person singular\n",
            "    ist est\n",
            "FW-CC: foreign word: conjunction, coordinating\n",
            "    et ma mais und aber och nec y\n",
            "FW-CD: foreign word: numeral, cardinal\n",
            "    une cinq deux sieben unam zwei\n",
            "FW-CS: foreign word: conjunction, subordinating\n",
            "    bevor quam ma\n",
            "FW-DT: foreign word: determiner/pronoun, singular\n",
            "    hoc\n",
            "FW-DT+BEZ: foreign word: determiner + verb 'to be', present tense, 3rd person singular\n",
            "    c'est\n",
            "FW-DTS: foreign word: determiner/pronoun, plural\n",
            "    haec\n",
            "FW-HV: foreign word: verb 'to have', present tense, not 3rd person singular\n",
            "    habe\n",
            "FW-IN: foreign word: preposition\n",
            "    ad de en a par con dans ex von auf super post sine sur sub avec per\n",
            "    inter sans pour pendant in di\n",
            "FW-IN+AT: foreign word: preposition + article\n",
            "    della des du aux zur d'un del dell'\n",
            "FW-IN+NN: foreign word: preposition + noun, singular, common\n",
            "    d'etat d'hotel d'argent d'identite d'art\n",
            "FW-IN+NP: foreign word: preposition + noun, singular, proper\n",
            "    d'Yquem d'Eiffel\n",
            "FW-JJ: foreign word: adjective\n",
            "    avant Espagnol sinfonica Siciliana Philharmonique grand publique haute\n",
            "    noire bouffe Douce meme humaine bel serieuses royaux anticus presto\n",
            "    Sovietskaya Bayerische comique schwarzen ...\n",
            "FW-JJR: foreign word: adjective, comparative\n",
            "    fortiori\n",
            "FW-JJT: foreign word: adjective, superlative\n",
            "    optimo\n",
            "FW-NN: foreign word: noun, singular, common\n",
            "    ballet esprit ersatz mano chatte goutte sang Fledermaus oud def kolkhoz\n",
            "    roi troika canto boite blutwurst carne muzyka bonheur monde piece force\n",
            "    ...\n",
            "FW-NN$: foreign word: noun, singular, common, genitive\n",
            "    corporis intellectus arte's dei aeternitatis senioritatis curiae\n",
            "    patronne's chambre's\n",
            "FW-NNS: foreign word: noun, plural, common\n",
            "    al culpas vopos boites haflis kolkhozes augen tyrannis alpha-beta-\n",
            "    gammas metis banditos rata phis negociants crus Einsatzkommandos\n",
            "    kamikaze wohaws sabinas zorrillas palazzi engages coureurs corroborees\n",
            "    yori Ubermenschen ...\n",
            "FW-NP: foreign word: noun, singular, proper\n",
            "    Karshilama Dieu Rundfunk Afrique Espanol Afrika Spagna Gott Carthago\n",
            "    deus\n",
            "FW-NPS: foreign word: noun, plural, proper\n",
            "    Svenskarna Atlantes Dieux\n",
            "FW-NR: foreign word: noun, singular, adverbial\n",
            "    heute morgen aujourd'hui hoy\n",
            "FW-OD: foreign word: numeral, ordinal\n",
            "    18e 17e quintus\n",
            "FW-PN: foreign word: pronoun, nominal\n",
            "    hoc\n",
            "FW-PP$: foreign word: determiner, possessive\n",
            "    mea mon deras vos\n",
            "FW-PPL: foreign word: pronoun, singular, reflexive\n",
            "    se\n",
            "FW-PPL+VBZ: foreign word: pronoun, singular, reflexive + verb, present tense, 3rd person singular\n",
            "    s'excuse s'accuse\n",
            "FW-PPO: pronoun, personal, accusative\n",
            "    lui me moi mi\n",
            "FW-PPO+IN: foreign word: pronoun, personal, accusative + preposition\n",
            "    mecum tecum\n",
            "FW-PPS: foreign word: pronoun, personal, nominative, 3rd person singular\n",
            "    il\n",
            "FW-PPSS: foreign word: pronoun, personal, nominative, not 3rd person singular\n",
            "    ich vous sie je\n",
            "FW-PPSS+HV: foreign word: pronoun, personal, nominative, not 3rd person singular + verb 'to have', present tense, not 3rd person singular\n",
            "    j'ai\n",
            "FW-QL: foreign word: qualifier\n",
            "    minus\n",
            "FW-RB: foreign word: adverb\n",
            "    bas assai deja um wiederum cito velociter vielleicht simpliciter non zu\n",
            "    domi nuper sic forsan olim oui semper tout despues hors\n",
            "FW-RB+CC: foreign word: adverb + conjunction, coordinating\n",
            "    forisque\n",
            "FW-TO+VB: foreign word: infinitival to + verb, infinitive\n",
            "    d'entretenir\n",
            "FW-UH: foreign word: interjection\n",
            "    sayonara bien adieu arigato bonjour adios bueno tchalo ciao o\n",
            "FW-VB: foreign word: verb, present tense, not 3rd person singular, imperative or infinitive\n",
            "    nolo contendere vive fermate faciunt esse vade noli tangere dites duces\n",
            "    meminisse iuvabit gosaimasu voulez habla ksu'u'peli'afo lacheln miuchi\n",
            "    say allons strafe portant\n",
            "FW-VBD: foreign word: verb, past tense\n",
            "    stabat peccavi audivi\n",
            "FW-VBG: foreign word: verb, present participle or gerund\n",
            "    nolens volens appellant seq. obliterans servanda dicendi delenda\n",
            "FW-VBN: foreign word: verb, past participle\n",
            "    vue verstrichen rasa verboten engages\n",
            "FW-VBZ: foreign word: verb, present tense, 3rd person singular\n",
            "    gouverne sinkt sigue diapiace\n",
            "FW-WDT: foreign word: WH-determiner\n",
            "    quo qua quod que quok\n",
            "FW-WPO: foreign word: WH-pronoun, accusative\n",
            "    quibusdam\n",
            "FW-WPS: foreign word: WH-pronoun, nominative\n",
            "    qui\n",
            "HV: verb 'to have', uninflected present tense, infinitive or imperative\n",
            "    have hast\n",
            "HV*: verb 'to have', uninflected present tense or imperative, negated\n",
            "    haven't ain't\n",
            "HV+TO: verb 'to have', uninflected present tense + infinitival to\n",
            "    hafta\n",
            "HVD: verb 'to have', past tense\n",
            "    had\n",
            "HVD*: verb 'to have', past tense, negated\n",
            "    hadn't\n",
            "HVG: verb 'to have', present participle or gerund\n",
            "    having\n",
            "HVN: verb 'to have', past participle\n",
            "    had\n",
            "HVZ: verb 'to have', present tense, 3rd person singular\n",
            "    has hath\n",
            "HVZ*: verb 'to have', present tense, 3rd person singular, negated\n",
            "    hasn't ain't\n",
            "IN: preposition\n",
            "    of in for by considering to on among at through with under into\n",
            "    regarding than since despite according per before toward against as\n",
            "    after during including between without except upon out over ...\n",
            "IN+IN: preposition, hyphenated pair\n",
            "    f'ovuh\n",
            "IN+PPO: preposition + pronoun, personal, accusative\n",
            "    t'hi-im\n",
            "JJ: adjective\n",
            "    ecent over-all possible hard-fought favorable hard meager fit such\n",
            "    widespread outmoded inadequate ambiguous grand clerical effective\n",
            "    orderly federal foster general proportionate ...\n",
            "JJ$: adjective, genitive\n",
            "    Great's\n",
            "JJ+JJ: adjective, hyphenated pair\n",
            "    big-large long-far\n",
            "JJR: adjective, comparative\n",
            "    greater older further earlier later freer franker wider better deeper\n",
            "    firmer tougher faster higher bigger worse younger lighter nicer slower\n",
            "    happier frothier Greater newer Elder ...\n",
            "JJR+CS: adjective + conjunction, coordinating\n",
            "    lighter'n\n",
            "JJS: adjective, semantically superlative\n",
            "    top chief principal northernmost master key head main tops utmost\n",
            "    innermost foremost uppermost paramount topmost\n",
            "JJT: adjective, superlative\n",
            "    best largest coolest calmest latest greatest earliest simplest\n",
            "    strongest newest fiercest unhappiest worst youngest worthiest fastest\n",
            "    hottest fittest lowest finest smallest staunchest ...\n",
            "MD: modal auxillary\n",
            "    should may might will would must can could shall ought need wilt\n",
            "MD*: modal auxillary, negated\n",
            "    cannot couldn't wouldn't can't won't shouldn't shan't mustn't musn't\n",
            "MD+HV: modal auxillary + verb 'to have', uninflected form\n",
            "    shouldda musta coulda must've woulda could've\n",
            "MD+PPSS: modal auxillary + pronoun, personal, nominative, not 3rd person singular\n",
            "    willya\n",
            "MD+TO: modal auxillary + infinitival to\n",
            "    oughta\n",
            "NN: noun, singular, common\n",
            "    failure burden court fire appointment awarding compensation Mayor\n",
            "    interim committee fact effect airport management surveillance jail\n",
            "    doctor intern extern night weekend duty legislation Tax Office ...\n",
            "NN$: noun, singular, common, genitive\n",
            "    season's world's player's night's chapter's golf's football's\n",
            "    baseball's club's U.'s coach's bride's bridegroom's board's county's\n",
            "    firm's company's superintendent's mob's Navy's ...\n",
            "NN+BEZ: noun, singular, common + verb 'to be', present tense, 3rd person singular\n",
            "    water's camera's sky's kid's Pa's heat's throat's father's money's\n",
            "    undersecretary's granite's level's wife's fat's Knife's fire's name's\n",
            "    hell's leg's sun's roulette's cane's guy's kind's baseball's ...\n",
            "NN+HVD: noun, singular, common + verb 'to have', past tense\n",
            "    Pa'd\n",
            "NN+HVZ: noun, singular, common + verb 'to have', present tense, 3rd person singular\n",
            "    guy's Knife's boat's summer's rain's company's\n",
            "NN+IN: noun, singular, common + preposition\n",
            "    buncha\n",
            "NN+MD: noun, singular, common + modal auxillary\n",
            "    cowhand'd sun'll\n",
            "NN+NN: noun, singular, common, hyphenated pair\n",
            "    stomach-belly\n",
            "NNS: noun, plural, common\n",
            "    irregularities presentments thanks reports voters laws legislators\n",
            "    years areas adjustments chambers $100 bonds courts sales details raises\n",
            "    sessions members congressmen votes polls calls ...\n",
            "NNS$: noun, plural, common, genitive\n",
            "    taxpayers' children's members' States' women's cutters' motorists'\n",
            "    steelmakers' hours' Nations' lawyers' prisoners' architects' tourists'\n",
            "    Employers' secretaries' Rogues' ...\n",
            "NNS+MD: noun, plural, common + modal auxillary\n",
            "    duds'd oystchers'll\n",
            "NP: noun, singular, proper\n",
            "    Fulton Atlanta September-October Durwood Pye Ivan Allen Jr. Jan.\n",
            "    Alpharetta Grady William B. Hartsfield Pearl Williams Aug. Berry J. M.\n",
            "    Cheshire Griffin Opelika Ala. E. Pelham Snodgrass ...\n",
            "NP$: noun, singular, proper, genitive\n",
            "    Green's Landis' Smith's Carreon's Allison's Boston's Spahn's Willie's\n",
            "    Mickey's Milwaukee's Mays' Howsam's Mantle's Shaw's Wagner's Rickey's\n",
            "    Shea's Palmer's Arnold's Broglio's ...\n",
            "NP+BEZ: noun, singular, proper + verb 'to be', present tense, 3rd person singular\n",
            "    W.'s Ike's Mack's Jack's Kate's Katharine's Black's Arthur's Seaton's\n",
            "    Buckhorn's Breed's Penny's Rob's Kitty's Blackwell's Myra's Wally's\n",
            "    Lucille's Springfield's Arlene's\n",
            "NP+HVZ: noun, singular, proper + verb 'to have', present tense, 3rd person singular\n",
            "    Bill's Guardino's Celie's Skolman's Crosson's Tim's Wally's\n",
            "NP+MD: noun, singular, proper + modal auxillary\n",
            "    Gyp'll John'll\n",
            "NPS: noun, plural, proper\n",
            "    Chases Aderholds Chapelles Armisteads Lockies Carbones French Marskmen\n",
            "    Toppers Franciscans Romans Cadillacs Masons Blacks Catholics British\n",
            "    Dixiecrats Mississippians Congresses ...\n",
            "NPS$: noun, plural, proper, genitive\n",
            "    Republicans' Orioles' Birds' Yanks' Redbirds' Bucs' Yankees' Stevenses'\n",
            "    Geraghtys' Burkes' Wackers' Achaeans' Dresbachs' Russians' Democrats'\n",
            "    Gershwins' Adventists' Negroes' Catholics' ...\n",
            "NR: noun, singular, adverbial\n",
            "    Friday home Wednesday Tuesday Monday Sunday Thursday yesterday tomorrow\n",
            "    tonight West East Saturday west left east downtown north northeast\n",
            "    southeast northwest North South right ...\n",
            "NR$: noun, singular, adverbial, genitive\n",
            "    Saturday's Monday's yesterday's tonight's tomorrow's Sunday's\n",
            "    Wednesday's Friday's today's Tuesday's West's Today's South's\n",
            "NR+MD: noun, singular, adverbial + modal auxillary\n",
            "    today'll\n",
            "NRS: noun, plural, adverbial\n",
            "    Sundays Mondays Saturdays Wednesdays Souths Fridays\n",
            "OD: numeral, ordinal\n",
            "    first 13th third nineteenth 2d 61st second sixth eighth ninth twenty-\n",
            "    first eleventh 50th eighteenth- Thirty-ninth 72nd 1/20th twentieth\n",
            "    mid-19th thousandth 350th sixteenth 701st ...\n",
            "PN: pronoun, nominal\n",
            "    none something everything one anyone nothing nobody everybody everyone\n",
            "    anybody anything someone no-one nothin\n",
            "PN$: pronoun, nominal, genitive\n",
            "    one's someone's anybody's nobody's everybody's anyone's everyone's\n",
            "PN+BEZ: pronoun, nominal + verb 'to be', present tense, 3rd person singular\n",
            "    nothing's everything's somebody's nobody's someone's\n",
            "PN+HVD: pronoun, nominal + verb 'to have', past tense\n",
            "    nobody'd\n",
            "PN+HVZ: pronoun, nominal + verb 'to have', present tense, 3rd person singular\n",
            "    nobody's somebody's one's\n",
            "PN+MD: pronoun, nominal + modal auxillary\n",
            "    someone'll somebody'll anybody'd\n",
            "PP$: determiner, possessive\n",
            "    our its his their my your her out thy mine thine\n",
            "PP$$: pronoun, possessive\n",
            "    ours mine his hers theirs yours\n",
            "PPL: pronoun, singular, reflexive\n",
            "    itself himself myself yourself herself oneself ownself\n",
            "PPLS: pronoun, plural, reflexive\n",
            "    themselves ourselves yourselves\n",
            "PPO: pronoun, personal, accusative\n",
            "    them it him me us you 'em her thee we'uns\n",
            "PPS: pronoun, personal, nominative, 3rd person singular\n",
            "    it he she thee\n",
            "PPS+BEZ: pronoun, personal, nominative, 3rd person singular + verb 'to be', present tense, 3rd person singular\n",
            "    it's he's she's\n",
            "PPS+HVD: pronoun, personal, nominative, 3rd person singular + verb 'to have', past tense\n",
            "    she'd he'd it'd\n",
            "PPS+HVZ: pronoun, personal, nominative, 3rd person singular + verb 'to have', present tense, 3rd person singular\n",
            "    it's he's she's\n",
            "PPS+MD: pronoun, personal, nominative, 3rd person singular + modal auxillary\n",
            "    he'll she'll it'll he'd it'd she'd\n",
            "PPSS: pronoun, personal, nominative, not 3rd person singular\n",
            "    they we I you ye thou you'uns\n",
            "PPSS+BEM: pronoun, personal, nominative, not 3rd person singular + verb 'to be', present tense, 1st person singular\n",
            "    I'm Ahm\n",
            "PPSS+BER: pronoun, personal, nominative, not 3rd person singular + verb 'to be', present tense, 2nd person singular or all persons plural\n",
            "    we're you're they're\n",
            "PPSS+BEZ: pronoun, personal, nominative, not 3rd person singular + verb 'to be', present tense, 3rd person singular\n",
            "    you's\n",
            "PPSS+BEZ*: pronoun, personal, nominative, not 3rd person singular + verb 'to be', present tense, 3rd person singular, negated\n",
            "    'tain't\n",
            "PPSS+HV: pronoun, personal, nominative, not 3rd person singular + verb 'to have', uninflected present tense\n",
            "    I've we've they've you've\n",
            "PPSS+HVD: pronoun, personal, nominative, not 3rd person singular + verb 'to have', past tense\n",
            "    I'd you'd we'd they'd\n",
            "PPSS+MD: pronoun, personal, nominative, not 3rd person singular + modal auxillary\n",
            "    you'll we'll I'll we'd I'd they'll they'd you'd\n",
            "PPSS+VB: pronoun, personal, nominative, not 3rd person singular + verb 'to verb', uninflected present tense\n",
            "    y'know\n",
            "QL: qualifier, pre\n",
            "    well less very most so real as highly fundamentally even how much\n",
            "    remarkably somewhat more completely too thus ill deeply little overly\n",
            "    halfway almost impossibly far severly such ...\n",
            "QLP: qualifier, post\n",
            "    indeed enough still 'nuff\n",
            "RB: adverb\n",
            "    only often generally also nevertheless upon together back newly no\n",
            "    likely meanwhile near then heavily there apparently yet outright fully\n",
            "    aside consistently specifically formally ever just ...\n",
            "RB$: adverb, genitive\n",
            "    else's\n",
            "RB+BEZ: adverb + verb 'to be', present tense, 3rd person singular\n",
            "    here's there's\n",
            "RB+CS: adverb + conjunction, coordinating\n",
            "    well's soon's\n",
            "RBR: adverb, comparative\n",
            "    further earlier better later higher tougher more harder longer sooner\n",
            "    less faster easier louder farther oftener nearer cheaper slower tighter\n",
            "    lower worse heavier quicker ...\n",
            "RBR+CS: adverb, comparative + conjunction, coordinating\n",
            "    more'n\n",
            "RBT: adverb, superlative\n",
            "    most best highest uppermost nearest brightest hardest fastest deepest\n",
            "    farthest loudest ...\n",
            "RN: adverb, nominal\n",
            "    here afar then\n",
            "RP: adverb, particle\n",
            "    up out off down over on in about through across after\n",
            "RP+IN: adverb, particle + preposition\n",
            "    out'n outta\n",
            "TO: infinitival to\n",
            "    to t'\n",
            "TO+VB: infinitival to + verb, infinitive\n",
            "    t'jawn t'lah\n",
            "UH: interjection\n",
            "    Hurrah bang whee hmpf ah goodbye oops oh-the-pain-of-it ha crunch say\n",
            "    oh why see well hello lo alas tarantara rum-tum-tum gosh hell keerist\n",
            "    Jesus Keeeerist boy c'mon 'mon goddamn bah hoo-pig damn ...\n",
            "VB: verb, base: uninflected present, imperative or infinitive\n",
            "    investigate find act follow inure achieve reduce take remedy re-set\n",
            "    distribute realize disable feel receive continue place protect\n",
            "    eliminate elaborate work permit run enter force ...\n",
            "VB+AT: verb, base: uninflected present or infinitive + article\n",
            "    wanna\n",
            "VB+IN: verb, base: uninflected present, imperative or infinitive + preposition\n",
            "    lookit\n",
            "VB+JJ: verb, base: uninflected present, imperative or infinitive + adjective\n",
            "    die-dead\n",
            "VB+PPO: verb, uninflected present tense + pronoun, personal, accusative\n",
            "    let's lemme gimme\n",
            "VB+RP: verb, imperative + adverbial particle\n",
            "    g'ahn c'mon\n",
            "VB+TO: verb, base: uninflected present, imperative or infinitive + infinitival to\n",
            "    wanta wanna\n",
            "VB+VB: verb, base: uninflected present, imperative or infinitive; hypenated pair\n",
            "    say-speak\n",
            "VBD: verb, past tense\n",
            "    said produced took recommended commented urged found added praised\n",
            "    charged listed became announced brought attended wanted voted defeated\n",
            "    received got stood shot scheduled feared promised made ...\n",
            "VBG: verb, present participle or gerund\n",
            "    modernizing improving purchasing Purchasing lacking enabling pricing\n",
            "    keeping getting picking entering voting warning making strengthening\n",
            "    setting neighboring attending participating moving ...\n",
            "VBG+TO: verb, present participle + infinitival to\n",
            "    gonna\n",
            "VBN: verb, past participle\n",
            "    conducted charged won received studied revised operated accepted\n",
            "    combined experienced recommended effected granted seen protected\n",
            "    adopted retarded notarized selected composed gotten printed ...\n",
            "VBN+TO: verb, past participle + infinitival to\n",
            "    gotta\n",
            "VBZ: verb, present tense, 3rd person singular\n",
            "    deserves believes receives takes goes expires says opposes starts\n",
            "    permits expects thinks faces votes teaches holds calls fears spends\n",
            "    collects backs eliminates sets flies gives seeks reads ...\n",
            "WDT: WH-determiner\n",
            "    which what whatever whichever whichever-the-hell\n",
            "WDT+BER: WH-determiner + verb 'to be', present tense, 2nd person singular or all persons plural\n",
            "    what're\n",
            "WDT+BER+PP: WH-determiner + verb 'to be', present, 2nd person singular or all persons plural + pronoun, personal, nominative, not 3rd person singular\n",
            "    whaddya\n",
            "WDT+BEZ: WH-determiner + verb 'to be', present tense, 3rd person singular\n",
            "    what's\n",
            "WDT+DO+PPS: WH-determiner + verb 'to do', uninflected present tense + pronoun, personal, nominative, not 3rd person singular\n",
            "    whaddya\n",
            "WDT+DOD: WH-determiner + verb 'to do', past tense\n",
            "    what'd\n",
            "WDT+HVZ: WH-determiner + verb 'to have', present tense, 3rd person singular\n",
            "    what's\n",
            "WP$: WH-pronoun, genitive\n",
            "    whose whosever\n",
            "WPO: WH-pronoun, accusative\n",
            "    whom that who\n",
            "WPS: WH-pronoun, nominative\n",
            "    that who whoever whosoever what whatsoever\n",
            "WPS+BEZ: WH-pronoun, nominative + verb 'to be', present, 3rd person singular\n",
            "    that's who's\n",
            "WPS+HVD: WH-pronoun, nominative + verb 'to have', past tense\n",
            "    who'd\n",
            "WPS+HVZ: WH-pronoun, nominative + verb 'to have', present tense, 3rd person singular\n",
            "    who's that's\n",
            "WPS+MD: WH-pronoun, nominative + modal auxillary\n",
            "    who'll that'd who'd that'll\n",
            "WQL: WH-qualifier\n",
            "    however how\n",
            "WRB: WH-adverb\n",
            "    however when where why whereby wherever how whenever whereon wherein\n",
            "    wherewith wheare wherefore whereof howsabout\n",
            "WRB+BER: WH-adverb + verb 'to be', present, 2nd person singular or all persons plural\n",
            "    where're\n",
            "WRB+BEZ: WH-adverb + verb 'to be', present, 3rd person singular\n",
            "    how's where's\n",
            "WRB+DO: WH-adverb + verb 'to do', present, not 3rd person singular\n",
            "    howda\n",
            "WRB+DOD: WH-adverb + verb 'to do', past tense\n",
            "    where'd how'd\n",
            "WRB+DOD*: WH-adverb + verb 'to do', past tense, negated\n",
            "    whyn't\n",
            "WRB+DOZ: WH-adverb + verb 'to do', present tense, 3rd person singular\n",
            "    how's\n",
            "WRB+IN: WH-adverb + preposition\n",
            "    why'n\n",
            "WRB+MD: WH-adverb + modal auxillary\n",
            "    where'd\n",
            "None\n",
            "\n",
            "Details of a specific tag :\n",
            "NNS: noun, plural, common\n",
            "    irregularities presentments thanks reports voters laws legislators\n",
            "    years areas adjustments chambers $100 bonds courts sales details raises\n",
            "    sessions members congressmen votes polls calls ...\n",
            "None\n",
            "\n",
            "Details on several related tagsets, using regular expression:\n",
            "WDT: WH-determiner\n",
            "    which what whatever whichever whichever-the-hell\n",
            "WDT+BER: WH-determiner + verb 'to be', present tense, 2nd person singular or all persons plural\n",
            "    what're\n",
            "WDT+BER+PP: WH-determiner + verb 'to be', present, 2nd person singular or all persons plural + pronoun, personal, nominative, not 3rd person singular\n",
            "    whaddya\n",
            "WDT+BEZ: WH-determiner + verb 'to be', present tense, 3rd person singular\n",
            "    what's\n",
            "WDT+DO+PPS: WH-determiner + verb 'to do', uninflected present tense + pronoun, personal, nominative, not 3rd person singular\n",
            "    whaddya\n",
            "WDT+DOD: WH-determiner + verb 'to do', past tense\n",
            "    what'd\n",
            "WDT+HVZ: WH-determiner + verb 'to have', present tense, 3rd person singular\n",
            "    what's\n",
            "WP$: WH-pronoun, genitive\n",
            "    whose whosever\n",
            "WPO: WH-pronoun, accusative\n",
            "    whom that who\n",
            "WPS: WH-pronoun, nominative\n",
            "    that who whoever whosoever what whatsoever\n",
            "WPS+BEZ: WH-pronoun, nominative + verb 'to be', present, 3rd person singular\n",
            "    that's who's\n",
            "WPS+HVD: WH-pronoun, nominative + verb 'to have', past tense\n",
            "    who'd\n",
            "WPS+HVZ: WH-pronoun, nominative + verb 'to have', present tense, 3rd person singular\n",
            "    who's that's\n",
            "WPS+MD: WH-pronoun, nominative + modal auxillary\n",
            "    who'll that'd who'd that'll\n",
            "WQL: WH-qualifier\n",
            "    however how\n",
            "WRB: WH-adverb\n",
            "    however when where why whereby wherever how whenever whereon wherein\n",
            "    wherewith wheare wherefore whereof howsabout\n",
            "WRB+BER: WH-adverb + verb 'to be', present, 2nd person singular or all persons plural\n",
            "    where're\n",
            "WRB+BEZ: WH-adverb + verb 'to be', present, 3rd person singular\n",
            "    how's where's\n",
            "WRB+DO: WH-adverb + verb 'to do', present, not 3rd person singular\n",
            "    howda\n",
            "WRB+DOD: WH-adverb + verb 'to do', past tense\n",
            "    where'd how'd\n",
            "WRB+DOD*: WH-adverb + verb 'to do', past tense, negated\n",
            "    whyn't\n",
            "WRB+DOZ: WH-adverb + verb 'to do', present tense, 3rd person singular\n",
            "    how's\n",
            "WRB+IN: WH-adverb + preposition\n",
            "    why'n\n",
            "WRB+MD: WH-adverb + modal auxillary\n",
            "    where'd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package tagsets_json to /root/nltk_data...\n",
            "[nltk_data]   Unzipping help/tagsets_json.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q10.Write a python NLTK program tofind the number of male and female names in the names corpus. Print 10 male and female names.**"
      ],
      "metadata": {
        "id": "Z-L9JZuZXqWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import names\n",
        "nltk.download('names')\n",
        "print(\"\\nNumber of male names:\")\n",
        "print (len(names.words('male.txt')))\n",
        "print(\"\\nNumber of female names:\")\n",
        "print (len(names.words('female.txt')))\n",
        "male_names = names.words('male.txt')\n",
        "female_names = names.words('female.txt')\n",
        "print(\"\\nFirst 10 male names:\")\n",
        "print (male_names[0:15])\n",
        "print(\"\\nFirst 10 female names:\")\n",
        "print (female_names[0:15])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLjpGFG_Xpqh",
        "outputId": "58fb9277-0cdb-4569-c4ad-981dd46f11fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of male names:\n",
            "2943\n",
            "\n",
            "Number of female names:\n",
            "5001\n",
            "\n",
            "First 10 male names:\n",
            "['Aamir', 'Aaron', 'Abbey', 'Abbie', 'Abbot', 'Abbott', 'Abby', 'Abdel', 'Abdul', 'Abdulkarim', 'Abdullah', 'Abe', 'Abel', 'Abelard', 'Abner']\n",
            "\n",
            "First 10 female names:\n",
            "['Abagael', 'Abagail', 'Abbe', 'Abbey', 'Abbi', 'Abbie', 'Abby', 'Abigael', 'Abigail', 'Abigale', 'Abra', 'Acacia', 'Ada', 'Adah', 'Adaline']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/names.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q11.Write a python program to demonstarate lemmatization with NLTK**"
      ],
      "metadata": {
        "id": "T77FYy0LAgLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "lem=WordNetLemmatizer()\n",
        "word=input(\"Enter the word to lemmatized: \")\n",
        "print(f\"{word}: \",lem.lemmatize(word))\n",
        "print(f\"{word}: \",lem.lemmatize(word,pos='a'))"
      ],
      "metadata": {
        "id": "5OStjuShXzxC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "785a0b25-62c2-45e1-ac1c-edcb9fd1f1e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the word to lemmatized: better\n",
            "better:  better\n",
            "better:  good\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q12.Write a python program to demonstrate Stemming with NLTK.**"
      ],
      "metadata": {
        "id": "aQmnmJ5uK7r0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt_tab')\n",
        "ps = PorterStemmer()\n",
        "sentence = input(\"Enter the word: \")\n",
        "words = word_tokenize(sentence)\n",
        "for w in words:\n",
        "    print(w, \" : \", ps.stem(w))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUtOIbWKCA44",
        "outputId": "4481c348-62fd-4098-9cf9-a1c584751567"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the word: the sun rises in the east\n",
            "the  :  the\n",
            "sun  :  sun\n",
            "rises  :  rise\n",
            "in  :  in\n",
            "the  :  the\n",
            "east  :  east\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q13.Write a python program for NLP analysis of Restaurant review.**"
      ],
      "metadata": {
        "id": "WsOj9-ydtwaf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from textblob import TextBlob\n",
        "I=[\"Review liked\", \"Wow loved this place\",\n",
        "   \"crust is not good\", \"not tasty and the texture was just nasty\",\n",
        "   \"stopped by during the last may bank holeday\",\"The fries were great to\",\n",
        "   \"A great touch\",\"service was very prompt.\"\n",
        "   ]\n",
        "for r in I:\n",
        "  s=TextBlob(r).sentiment.polarity\n",
        "  if s>0:\n",
        "    print(f'Positive review with : {s}')\n",
        "  elif s==0:\n",
        "    print(f'Negative review with : {s}')\n",
        "  else:\n",
        "    print(f'negative review with : {s}')\n"
      ],
      "metadata": {
        "id": "86HWMcs1LEnC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5599e84-bb51-4d0c-97f2-37a3732aa118"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive review with : 0.6\n",
            "Positive review with : 0.39999999999999997\n",
            "negative review with : -0.35\n",
            "negative review with : -1.0\n",
            "Negative review with : 0.0\n",
            "Positive review with : 0.8\n",
            "Positive review with : 0.8\n",
            "Positive review with : 0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q14.Write a program for Twitter sentiment Analysis using Python.**"
      ],
      "metadata": {
        "id": "hT_LJKDW8BO7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from textblob import TextBlob\n",
        "\n",
        "# Open the file with the correct encoding (e.g., 'latin-1')\n",
        "with open('twitter sentiment analysis.csv', 'r', encoding='latin-1') as file:\n",
        "    reader = csv.reader(file)\n",
        "    next(reader)  # Skip the header row if it exists\n",
        "    positive = 0\n",
        "    negative = 0\n",
        "    neutral = 0\n",
        "    for row in reader:\n",
        "        # Check if the row has at least 2 columns before accessing index 1\n",
        "        if len(row) > 1:\n",
        "            tweet_text = row[1].strip()\n",
        "            sentiment = TextBlob(tweet_text).sentiment.polarity\n",
        "            if sentiment > 0:\n",
        "                positive += 1\n",
        "            elif sentiment < 0:\n",
        "                negative += 1\n",
        "            else:\n",
        "                neutral += 1\n",
        "        #else:\n",
        "        #    print(f\"Skipping row: {row}\") # Optionally print skipped rows for debugging\n",
        "    print(\"Sentiment Analysis: \")\n",
        "    print(\"Positive tweets:\", positive)\n",
        "    print(\"Negative tweets:\", negative)\n",
        "    print(\"Neutral tweets:\", neutral)"
      ],
      "metadata": {
        "id": "4hwMFtlV_QCy",
        "outputId": "14d8e0d0-892d-409c-e460-74b918e71ab8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment Analysis: \n",
            "Positive tweets: 66\n",
            "Negative tweets: 38\n",
            "Neutral tweets: 42758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q15.Write a program for Sentiment Analysis using VADER.**"
      ],
      "metadata": {
        "id": "ayJpCc3P8V_b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install vaderSentiment"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-nKNlo54Tn8",
        "outputId": "863bb639-3169-435a-d272-03dd1087064a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting vaderSentiment\n",
            "  Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl.metadata (572 bytes)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from vaderSentiment) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->vaderSentiment) (2024.12.14)\n",
            "Downloading vaderSentiment-3.3.2-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/126.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m122.9/126.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import SentimentIntensityAnalyzer class from vaderSentiment.vaderSentiment module.\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "# Function to print sentiments of the sentence.\n",
        "def sentiment_scores(sentence):\n",
        "\n",
        "    # Create a SentimentIntensityAnalyzer object.\n",
        "    sid_obj = SentimentIntensityAnalyzer()\n",
        "\n",
        "    # polarity_scores method of SentimentIntensityAnalyzer object gives a sentiment dictionary.\n",
        "    # which contains pos, neg, neu, and compound scores.\n",
        "    sentiment_dict = sid_obj.polarity_scores(sentence)\n",
        "\n",
        "    print(\"Overall sentiment dictionary is : \", sentiment_dict)\n",
        "    print(\"Sentence was rated as \", sentiment_dict['neg']*100, \"% Negative\")\n",
        "    print(\"Sentence was rated as \", sentiment_dict['neu']*100, \"% Neutral\")\n",
        "    print(\"Sentence was rated as \", sentiment_dict['pos']*100, \"% Positive\")\n",
        "\n",
        "    print(\"Sentence Overall Rated As\", end=\" \")\n",
        "\n",
        "    # Decide sentiment as positive, negative, or neutral\n",
        "    if sentiment_dict['compound'] >= 0.05 :\n",
        "        print(\"Positive\")\n",
        "    elif sentiment_dict['compound'] <= -0.05 :\n",
        "        print(\"Negative\")\n",
        "    else :\n",
        "        print(\"Neutral\")\n",
        "\n",
        "# Driver code to test the function\n",
        "if __name__ == \"__main__\" :\n",
        "\n",
        "    print(\"\\n1st Statement:\")\n",
        "    sentence = \"Geeks For Geeks is the best portal for computer science engineering students.\"\n",
        "    sentiment_scores(sentence)\n",
        "\n",
        "    print(\"\\n2nd Statement:\")\n",
        "    sentence = \"Study is going on as usual.\"\n",
        "    sentiment_scores(sentence)\n",
        "\n",
        "    print(\"\\n3rd Statement:\")\n",
        "    sentence = \"I am very sad today.\"\n",
        "    sentiment_scores(sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKZSkeLqy2hE",
        "outputId": "2b619e4e-2a02-4d3f-8434-3d6d9f14793e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "1st Statement:\n",
            "Overall sentiment dictionary is :  {'neg': 0.175, 'neu': 0.562, 'pos': 0.263, 'compound': 0.5267}\n",
            "Sentence was rated as  17.5 % Negative\n",
            "Sentence was rated as  56.2 % Neutral\n",
            "Sentence was rated as  26.3 % Positive\n",
            "Sentence Overall Rated As Positive\n",
            "\n",
            "2nd Statement:\n",
            "Overall sentiment dictionary is :  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
            "Sentence was rated as  0.0 % Negative\n",
            "Sentence was rated as  100.0 % Neutral\n",
            "Sentence was rated as  0.0 % Positive\n",
            "Sentence Overall Rated As Neutral\n",
            "\n",
            "3rd Statement:\n",
            "Overall sentiment dictionary is :  {'neg': 0.459, 'neu': 0.541, 'pos': 0.0, 'compound': -0.5256}\n",
            "Sentence was rated as  45.9 % Negative\n",
            "Sentence was rated as  54.1 % Neutral\n",
            "Sentence was rated as  0.0 % Positive\n",
            "Sentence Overall Rated As Negative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_x15eOAK32B7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}